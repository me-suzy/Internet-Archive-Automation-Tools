import re
import requests
import json
import os
import shutil
import time
from pathlib import Path
from urllib.parse import quote_plus
from datetime import datetime

def process_filename(filepath):
    """ProceseazÄƒ numele fiÈ™ierului pentru a genera query de cÄƒutare."""
    filename = os.path.splitext(os.path.basename(filepath))[0]

    words_to_remove = [
        'retail', 'scan', 'ctrl', 'ocr', 'vp', 'istor',
        'trad', 'trad.', 'ed', 'edition', 'vol', 'tome'
    ]

    filename = re.sub(r'\([^)]*\)', '', filename)
    filename = re.sub(r'\d+', '', filename)
    words = re.findall(r'\w+', filename.lower())
    filtered_words = [word for word in words if word not in words_to_remove]

    return ' '.join(filtered_words), filtered_words

def calculate_relevance_score(query_words, result_title, result_creator=""):
    """CalculeazÄƒ scorul de relevanÈ›Äƒ Ã®ntre query È™i rezultat."""
    query_text = ' '.join(query_words).lower()
    title_text = (result_title + " " + result_creator).lower()

    query_text = re.sub(r'[^\w\s]', ' ', query_text)
    title_text = re.sub(r'[^\w\s]', ' ', title_text)

    query_words_set = set(query_text.split())
    title_words_set = set(title_text.split())

    common_words = query_words_set.intersection(title_words_set)

    if not query_words_set:
        return 0, common_words

    base_score = len(common_words) / len(query_words_set)
    important_words = list(query_words_set)[:3]
    important_matches = sum(1 for word in important_words if word in title_words_set)
    importance_bonus = important_matches / len(important_words) * 0.3

    return min(base_score + importance_bonus, 1.0), common_words

def search_archive_org(query, min_relevance_score=0.5):
    """CautÄƒ pe archive.org cu verificare de relevanÈ›Äƒ."""
    url = f"https://archive.org/advancedsearch.php?q={quote_plus(query)}&output=json&rows=5"

    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        data = response.json()
        docs = data.get('response', {}).get('docs', [])

        query_words = query.lower().split()
        relevant_results = []

        for doc in docs:
            title = doc.get('title', [''])
            if isinstance(title, list):
                title = title[0] if title else ''

            creator = doc.get('creator', [''])
            if isinstance(creator, list):
                creator = ', '.join(creator) if creator else ''

            relevance_score, common_words = calculate_relevance_score(query_words, title, creator)

            if relevance_score >= min_relevance_score:
                relevant_results.append({
                    'title': title,
                    'creator': creator,
                    'relevance_score': relevance_score,
                    'identifier': doc.get('identifier', ''),
                    'url': f"https://archive.org/details/{doc.get('identifier', '')}"
                })

        return len(relevant_results) > 0, relevant_results

    except Exception:
        return False, []

def calculate_folder_size(folder_path):
    """CalculeazÄƒ dimensiunea unui folder."""
    total_size = 0
    try:
        for dirpath, dirnames, filenames in os.walk(folder_path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                try:
                    total_size += os.path.getsize(filepath)
                except (OSError, FileNotFoundError):
                    pass
    except Exception:
        pass
    return total_size

def format_size(size_bytes):
    """FormateazÄƒ dimensiunea Ã®n unitÄƒÈ›i citibile."""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024
    return f"{size_bytes:.1f} TB"

def scan_and_delete_found_folders(base_directory, use_backup=True):
    """
    ScaneazÄƒ arhiva È™i È™terge automat SUBFOLDERELE gÄƒsite pe Archive.org.
    VERSIUNE CORECTATÄ‚ - testeazÄƒ fiecare subfolder individual.
    """
    base_path = Path(base_directory)
    if not base_path.exists():
        print(f"âŒ Directorul {base_directory} nu existÄƒ!")
        return

    backup_directory = None
    if use_backup:
        backup_directory = str(base_path.parent / "ARCHIVE_BACKUP")
        os.makedirs(backup_directory, exist_ok=True)
        print(f"ğŸ”’ Backup folder: {backup_directory}")
    else:
        print("âš ï¸  Modul È˜TERGERE DEFINITIVÄ‚ activat!")

    print("ğŸ” Scanez arhiva È™i caut pe Archive.org...")
    print("="*60)

    # GÄƒseÈ™te toate fiÈ™ierele
    print("ğŸ“„ Caut fiÈ™iere Ã®n arhivÄƒ...")
    file_extensions = ['.pdf', '.djvu', '.epub', '.rtf', '.doc', '.docx', '.txt']
    all_files = []
    for ext in file_extensions:
        files_found = list(base_path.rglob(f"*{ext}"))
        all_files.extend(files_found)
        print(f"   GÄƒsite {len(files_found)} fiÈ™iere {ext}")

    print(f"ğŸ“Š Total fiÈ™iere gÄƒsite: {len(all_files)}")

    # MODIFICARE CRITICÄ‚: GrupeazÄƒ pe SUBFOLDERE, nu pe autor
    print("ğŸ“‚ Grupez pe subfoldere individuale...")
    subfolders_to_process = {}

    for filepath in all_files:
        try:
            relative_path = Path(filepath).relative_to(base_path)

            # Pentru fiecare fiÈ™ier, identificÄƒ subfolderul direct
            if len(relative_path.parts) >= 2:
                # Format: author/book_folder/file.pdf
                author_name = relative_path.parts[0]
                book_folder = relative_path.parts[1]
                subfolder_key = f"{author_name}/{book_folder}"
                subfolder_path = base_path / author_name / book_folder

                if subfolder_key not in subfolders_to_process:
                    subfolders_to_process[subfolder_key] = {
                        'path': str(subfolder_path),
                        'files': [],
                        'author': author_name,
                        'book': book_folder
                    }

                subfolders_to_process[subfolder_key]['files'].append(str(filepath))
            elif len(relative_path.parts) == 2:
                # Format direct: author/file.pdf
                author_name = relative_path.parts[0]
                author_folder_path = base_path / author_name

                if author_name not in subfolders_to_process:
                    subfolders_to_process[author_name] = {
                        'path': str(author_folder_path),
                        'files': [],
                        'author': author_name,
                        'book': 'direct_files'
                    }

                subfolders_to_process[author_name]['files'].append(str(filepath))

        except ValueError:
            continue

    total_subfolders = len(subfolders_to_process)
    print(f"ğŸ“‚ GÄƒsite {total_subfolders} subfoldere de procesat")
    print("\nğŸ” Ãncep cÄƒutarea pe Archive.org...")
    print("="*60)

    subfolders_to_delete = []
    processed = 0
    found_count = 0
    start_time = time.time()

    # TESTEAZÄ‚ FIECARE SUBFOLDER INDIVIDUAL
    for subfolder_key, subfolder_info in subfolders_to_process.items():
        processed += 1

        elapsed = time.time() - start_time
        rate = processed / elapsed if elapsed > 0 else 0
        eta_seconds = (total_subfolders - processed) / rate if rate > 0 else 0
        eta_minutes = int(eta_seconds / 60)

        display_name = f"{subfolder_info['author']} - {subfolder_info['book']}"
        print(f"[{processed:3}/{total_subfolders}] {display_name[:50]:<50}", end=" ")

        if subfolder_info['files']:
            test_file = subfolder_info['files'][0]
            search_query, _ = process_filename(test_file)

            print(f"ğŸ” Caut...", end=" ")

            found, results = search_archive_org(search_query, min_relevance_score=0.5)

            if found and results:
                subfolder_size = calculate_folder_size(subfolder_info['path'])
                subfolders_to_delete.append({
                    'name': display_name,
                    'path': subfolder_info['path'],
                    'size': subfolder_size,
                    'files_count': len(subfolder_info['files']),
                    'query': search_query,
                    'best_match': results[0]['title'],
                    'relevance_score': results[0]['relevance_score'],
                    'author': subfolder_info['author'],
                    'book': subfolder_info['book']
                })
                found_count += 1
                print(f"âœ… GÄ‚SIT ({format_size(subfolder_size)}) ETA: {eta_minutes}min")
            else:
                print(f"âŒ Nu existÄƒ    ETA: {eta_minutes}min")
        else:
            print("âŒ FÄƒrÄƒ fiÈ™iere")

        time.sleep(0.3)

    # =================== PARTEA CARE LIPSEA ===================

    if not subfolders_to_delete:
        print("\nâœ… Nu s-au gÄƒsit subfoldere de È™ters. Toate cÄƒrÈ›ile din arhivÄƒ sunt unice!")
        return

    # CalculeazÄƒ statistici
    total_size = sum(subfolder['size'] for subfolder in subfolders_to_delete)

    print(f"\n{'='*60}")
    print(f"ğŸ“Š RAPORT FINAL")
    print(f"{'='*60}")
    print(f"Subfoldere procesate: {total_subfolders}")
    print(f"Subfoldere gÄƒsite pe Archive.org: {found_count}")
    print(f"SpaÈ›iu de eliberat: {format_size(total_size)}")
    print(f"Rata de succes: {found_count/total_subfolders*100:.1f}%")

    print(f"\nğŸ“‹ Primele 10 subfoldere de È™ters:")
    for i, subfolder in enumerate(subfolders_to_delete[:10], 1):
        print(f"   {i:2}. {subfolder['name'][:50]:<50} - {format_size(subfolder['size']):>8}")
        print(f"       GÄƒsit ca: {subfolder['best_match'][:60]}")

    if len(subfolders_to_delete) > 10:
        print(f"   ... È™i Ã®ncÄƒ {len(subfolders_to_delete) - 10} subfoldere")

    if use_backup:
        print(f"\nâš ï¸  ATENÈšIE!")
        print(f"   â€¢ Se vor muta {found_count} subfoldere Ã®n backup")
        print(f"   â€¢ Se vor elibera {format_size(total_size)} de spaÈ›iu")
        print(f"   â€¢ Backup folder: {backup_directory}")
    else:
        print(f"\nâš ï¸  ATENÈšIE - È˜TERGERE DEFINITIVÄ‚!")
        print(f"   â€¢ Se vor È˜TERGE DEFINITIV {found_count} subfoldere")
        print(f"   â€¢ Se vor elibera {format_size(total_size)} de spaÈ›iu")
        print(f"   â€¢ NU VA EXISTA BACKUP!")

    # Confirmarea finalÄƒ
    action_word = "muta Ã®n backup" if use_backup else "È™terge definitiv"
    confirmation = input(f"\nğŸ—‘ï¸  DoreÈ™ti sÄƒ {action_word} toate subfolderele gÄƒsite? (scrie 'DA' pentru confirmare): ")

    if confirmation.upper() == 'DA':
        action_msg = f"backup-ul {found_count} subfoldere..." if use_backup else f"È™tergerea DEFINITIVÄ‚ a {found_count} subfoldere..."
        print(f"\nğŸš€ Ãncep {action_msg}")
        print("="*60)

        deleted_count = 0
        deleted_size = 0

        for i, subfolder in enumerate(subfolders_to_delete, 1):
            try:
                action_verb = "Backup" if use_backup else "È˜terg"
                print(f"[{i:3}/{found_count}] {action_verb} {subfolder['name'][:40]:<40}", end=" ")

                if use_backup:
                    # MutÄƒ Ã®n backup cu timestamp
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    safe_name = subfolder['name'].replace('/', '_').replace('\\', '_')
                    backup_path = os.path.join(backup_directory, f"{safe_name}_{timestamp}")
                    shutil.move(subfolder['path'], backup_path)
                    print(f"âœ… Mutat ({format_size(subfolder['size'])})")
                else:
                    # È˜terge definitiv
                    shutil.rmtree(subfolder['path'])
                    print(f"âœ… È˜ters definitiv ({format_size(subfolder['size'])})")

                deleted_count += 1
                deleted_size += subfolder['size']

            except Exception as e:
                print(f"âŒ Eroare: {e}")

        print(f"\nğŸ‰ OPERAÈšIUNE COMPLETÄ‚!")
        print(f"{'='*60}")
        print(f"   âœ… Subfoldere procesate: {deleted_count}/{found_count}")
        print(f"   ğŸ’¾ SpaÈ›iu eliberat: {format_size(deleted_size)}")

        if use_backup:
            print(f"   ğŸ”’ Backup salvat Ã®n: {backup_directory}")
        else:
            print(f"   âš ï¸  Subfoldere È˜TERSE DEFINITIV - nu existÄƒ backup!")

        # SalveazÄƒ log-ul
        log_file = f"deleted_subfolders_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(subfolders_to_delete, f, ensure_ascii=False, indent=2)
        print(f"   ğŸ“„ Log salvat Ã®n: {log_file}")

    else:
        print("âŒ OperaÈ›iune anulatÄƒ.")



def main():
    base_directory = r"g:\ARHIVA\C"

    print("ğŸ—„ï¸  CURÄ‚ÈšARE AUTOMATÄ‚ ARHIVÄ‚")
    print("="*50)
    print("Acest program va:")
    print("â€¢ Scana toate folderele din arhivÄƒ")
    print("â€¢ CÄƒuta fiecare carte pe Archive.org")
    print("â€¢ È˜terge/Muta folderele gÄƒsite online")
    print("="*50)

    # ÃntreabÄƒ utilizatorul ce vrea
    backup_choice = input("\nCe vrei sÄƒ fac cu folderele gÄƒsite?\n1. MutÄƒ Ã®n backup (sigur)\n2. È˜terge definitiv (risky)\nAlege (1 sau 2): ")

    use_backup = backup_choice != "2"

    if use_backup:
        print("âœ… Folderele vor fi mutate Ã®n backup")
    else:
        print("âš ï¸  ATENÈšIE: Folderele vor fi È˜TERSE DEFINITIV!")
        confirm = input("EÈ™ti sigur? (scrie 'DA' pentru confirmare): ")
        if confirm != "DA":
            print("âŒ OperaÈ›iune anulatÄƒ")
            return

    input("\nApasÄƒ ENTER pentru a Ã®ncepe scanarea...")

    scan_and_delete_found_folders(base_directory, use_backup=use_backup)

if __name__ == "__main__":
    main()