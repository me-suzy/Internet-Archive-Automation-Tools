import time
import os
import shutil
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import tempfile
import json  # <- AdaugÄƒ asta
from datetime import datetime  # <- AdaugÄƒ asta
import re  # <- AdaugÄƒ asta

def setup_browser():
    """Se conecteazÄƒ la Chrome-ul deschis cu debug pe portul 9222."""
    from selenium.webdriver.chrome.service import Service

    chrome_options = Options()
    # Se conecteazÄƒ la Chrome-ul existent cu debug
    chrome_options.add_experimental_option("debuggerAddress", "127.0.0.1:9222")

    try:
        driver = webdriver.Chrome(options=chrome_options)
        print(f"      ğŸŒ Conectat la Chrome debug pe port 9222")
        return driver
    except Exception as e:
        print(f"      âŒ Nu pot conecta la Chrome debug: {e}")
        print(f"      ğŸ’¡ AsigurÄƒ-te cÄƒ ai rulat start_chrome_debug.bat mai Ã®ntÃ¢i!")
        raise e

def check_duplicate_with_browser(filepath, driver=None):
    """
    VerificÄƒ duplicatele folosind browserul real cu fiÈ™ierul REAL (OPTIMIZAT).
    """
    filename = os.path.basename(filepath)
    print(f"      ğŸŒ Testez: {filename}")

    if not os.path.exists(filepath):
        print(f"      âŒ FiÈ™ierul nu existÄƒ: {filepath}")
        return False, None

    should_quit_driver = False
    if driver is None:
        driver = setup_browser()
        should_quit_driver = True

    try:
        # NavigheazÄƒ rapid la upload
        driver.get("https://archive.org/upload/")

        # AÈ™teaptÄƒ doar elementul esenÈ›ial
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "input[type='file']"))
        )

        # SKIP setarea titlului - nu e necesarÄƒ pentru detectarea duplicatelor
        # Archive.org detecteazÄƒ oricum duplicatele dupÄƒ conÈ›inutul fiÈ™ierului

        # Upload direct fiÈ™ierul real
        file_input = driver.find_element(By.CSS_SELECTOR, "input[type='file']")
        print(f"      â¬†ï¸  Upload: {os.path.basename(filepath)}")
        file_input.send_keys(filepath)

        # Timp optimizat de aÈ™teptare
        print(f"      â³ Verific duplicatele...")
        time.sleep(8)  # Redus de la 15 la 8 secunde

        # Detectare rapidÄƒ a ID-ului
        detected_id = None

        try:
            # CautÄƒ direct elementul #item_id (cel mai rapid)
            item_id_element = driver.find_element(By.CSS_SELECTOR, "#item_id")
            detected_id = item_id_element.get_attribute('value') or item_id_element.text

            if detected_id:
                print(f"      ğŸ¯ ID: '{detected_id}'")

                # Verificare rapidÄƒ de sufix
                import re
                if re.search(r'_20\d{4,6}$', detected_id):
                    print(f"      âœ… DUPLICAT!")
                    return True, detected_id
                else:
                    print(f"      âŒ Unic")
                    return False, detected_id
            else:
                print(f"      â“ Nu pot extrage ID")
                return False, None

        except Exception as e:
            print(f"      âŒ Eroare: {e}")
            return False, None

    except Exception as e:
        print(f"      âŒ Eroare browser: {e}")
        return False, None
    finally:
        if should_quit_driver and driver:
            driver.quit()

def scan_and_delete_found_folders(base_directory):
    """
    Versiunea completÄƒ pentru curÄƒÈ›area arhivei.
    """
    base_path = Path(base_directory)
    if not base_path.exists():
        print(f"âŒ Directorul {base_directory} nu existÄƒ!")
        return

    print("ğŸ” CURÄ‚ÈšARE ARHIVÄ‚ cu DETECÈšIE DUPLICATE")
    print("="*50)

    # GÄƒseÈ™te toate fiÈ™ierele
    file_extensions = ['.pdf', '.djvu', '.epub', '.rtf', '.doc', '.docx']
    all_files = []
    for ext in file_extensions:
        files_found = list(base_path.rglob(f"*{ext}"))
        all_files.extend(files_found)
        print(f"   {ext}: {len(files_found)} fiÈ™iere")

    # GrupeazÄƒ pe foldere de autor
    folders_to_process = {}
    for filepath in all_files:
        try:
            relative_path = Path(filepath).relative_to(base_path)
            if relative_path.parts:
                author_folder_name = relative_path.parts[0]
                author_folder_path = base_path / author_folder_name

                if author_folder_name not in folders_to_process:
                    folders_to_process[author_folder_name] = {
                        'path': str(author_folder_path),
                        'files': []
                    }

                folders_to_process[author_folder_name]['files'].append(str(filepath))
        except ValueError:
            continue

    total_folders = len(folders_to_process)
    print(f"ğŸ“‚ Total foldere: {total_folders}")

    # Un singur driver pentru toate testele
    driver = setup_browser()

    folders_to_delete = []
    duplicates_found = 0

    try:
        for i, (folder_name, folder_info) in enumerate(folders_to_process.items(), 1):
            print(f"[{i:3}/{total_folders}] {folder_name[:40]:<40}", end=" ")

            if folder_info['files']:
                test_file = folder_info['files'][0]
                is_duplicate, detected_id = check_duplicate_with_browser(test_file, driver)

                if is_duplicate:
                    folder_size = calculate_folder_size(folder_info['path'])
                    folders_to_delete.append({
                        'name': folder_name,
                        'path': folder_info['path'],
                        'size': folder_size,
                        'detected_id': detected_id
                    })
                    duplicates_found += 1
                    print(f"âœ… DUPLICAT")
                else:
                    print(f"âŒ Unic")

                # PauzÄƒ minimÄƒ
                time.sleep(1)
            else:
                print(f"âŒ FÄƒrÄƒ fiÈ™iere")

    finally:
        driver.quit()

    if not folders_to_delete:
        print(f"\nâœ… Niciun duplicat gÄƒsit din {total_folders} foldere!")
        return

    # CalculeazÄƒ statistici
    total_size = sum(folder['size'] for folder in folders_to_delete)

    print(f"\n{'='*60}")
    print(f"ğŸ“Š DUPLICATE DETECTATE: {duplicates_found}/{total_folders}")
    print(f"ğŸ’¾ SpaÈ›iu de eliberat: {format_size(total_size)}")
    print(f"{'='*60}")

    for i, folder in enumerate(folders_to_delete[:5], 1):  # Primele 5
        print(f"   {i}. {folder['name']} â†’ {folder['detected_id']}")

    if len(folders_to_delete) > 5:
        print(f"   ... È™i Ã®ncÄƒ {len(folders_to_delete) - 5} foldere")

    confirmation = input(f"\nğŸ—‘ï¸  È˜TERGI {duplicates_found} foldere cu duplicate? (DA): ")

    if confirmation.upper() == 'DA':
        print(f"\nğŸš€ È˜terg {duplicates_found} foldere...")

        deleted_count = 0
        deleted_size = 0

        for i, folder in enumerate(folders_to_delete, 1):
            try:
                print(f"[{i:3}/{duplicates_found}] {folder['name'][:35]:<35}", end=" ")
                shutil.rmtree(folder['path'])
                deleted_count += 1
                deleted_size += folder['size']
                print(f"âœ… È˜ters")
            except Exception as e:
                print(f"âŒ Eroare: {e}")

        print(f"\nğŸ‰ COMPLET!")
        print(f"   âœ… È˜terse: {deleted_count}/{duplicates_found} foldere")
        print(f"   ğŸ’¾ Eliberat: {format_size(deleted_size)}")

        # Log
        log_file = f"deleted_duplicates_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(folders_to_delete, f, ensure_ascii=False, indent=2)
        print(f"   ğŸ“„ Log: {log_file}")
    else:
        print("âŒ Anulat")

def format_size(size_bytes):
    """FormateazÄƒ dimensiunea Ã®n unitÄƒÈ›i citibile."""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024
    return f"{size_bytes:.1f} TB"

def calculate_folder_size(folder_path):
    """CalculeazÄƒ dimensiunea unui folder."""
    total_size = 0
    try:
        for dirpath, dirnames, filenames in os.walk(folder_path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                try:
                    total_size += os.path.getsize(filepath)
                except (OSError, FileNotFoundError):
                    pass
    except Exception:
        pass
    return total_size

def scan_with_browser_automation(base_directory):
    """ScaneazÄƒ folosind automatizarea browserului."""
    base_path = Path(base_directory)

    print("ğŸ” Scanez cu automatizare browser real...")
    print("="*50)

    # GÄƒseÈ™te toate fiÈ™ierele
    all_files = []
    for ext in ['.pdf']:  # Testez doar PDF-uri pentru Ã®nceput
        all_files.extend(base_path.rglob(f"*{ext}"))

    # GrupeazÄƒ pe foldere
    folders_to_process = {}
    for filepath in all_files[:3]:  # Testez doar primele 3
        try:
            relative_path = Path(filepath).relative_to(base_path)
            if relative_path.parts:
                author_folder_name = relative_path.parts[0]
                if author_folder_name not in folders_to_process:
                    folders_to_process[author_folder_name] = {
                        'path': str(base_path / author_folder_name),
                        'files': [str(filepath)]
                    }
        except ValueError:
            continue

    duplicates_found = []

    for i, (folder_name, folder_info) in enumerate(folders_to_process.items(), 1):
        print(f"[{i}] {folder_name}")

        if folder_info['files']:
            test_file = folder_info['files'][0]
            is_duplicate, detected_id = check_duplicate_with_browser(test_file)

            if is_duplicate:
                duplicates_found.append({
                    'name': folder_name,
                    'path': folder_info['path'],
                    'detected_id': detected_id
                })
                print(f"   âœ… DUPLICAT: {detected_id}")
            else:
                print(f"   âŒ Unic")

    if duplicates_found:
        print(f"\nğŸ¯ GÄƒsite {len(duplicates_found)} duplicate!")
        for dup in duplicates_found:
            print(f"   - {dup['name']} â†’ {dup['detected_id']}")
    else:
        print("\nâœ… Niciun duplicat gÄƒsit")

def main():
    print("ğŸ¤– CURÄ‚ÈšARE ARHIVÄ‚ cu SELENIUM")
    print("ğŸ¯ DetecteazÄƒ duplicate prin upload real pe Archive.org")

    choice = input("PorneÈ™ti curÄƒÈ›area completÄƒ? (Y/N): ")
    if choice.upper() not in ['Y', 'YES', 'DA']:
        return

    base_directory = r"g:\ARHIVA\C++"
    scan_and_delete_found_folders(base_directory)

if __name__ == "__main__":
    main()