import re
import requests
import json
import os
from urllib.parse import quote_plus
import time
from pathlib import Path

def process_filename(filepath):
    """
    ProceseazÄƒ numele fiÈ™ierului eliminÃ¢nd cuvintele specifice,
    parantezele È™i cifrele pentru a genera un query de cÄƒutare.
    """
    # Extrage numele fiÈ™ierului fÄƒrÄƒ extensie È™i cale
    filename = os.path.splitext(os.path.basename(filepath))[0]

    # Lista cu cuvinte de eliminat
    words_to_remove = [
        'retail', 'scan', 'ctrl', 'ocr', 'vp', 'istor',
        'trad', 'trad.', 'ed', 'edition', 'vol', 'tome'
    ]

    # EliminÄƒ conÈ›inutul din parantezÄƒ
    filename = re.sub(r'\([^)]*\)', '', filename)

    # EliminÄƒ cifrele
    filename = re.sub(r'\d+', '', filename)

    # Ãmparte Ã®n cuvinte
    words = re.findall(r'\w+', filename.lower())

    # EliminÄƒ cuvintele specifice
    filtered_words = [word for word in words if word not in words_to_remove]

    # ReconstreÈ™te termenul de cÄƒutare
    search_query = ' '.join(filtered_words)

    return search_query, filtered_words

def search_archive_org_api(query, max_results=5):
    """
    CautÄƒ pe archive.org folosind API-ul oficial.
    """
    url = f"https://archive.org/advancedsearch.php?q={quote_plus(query)}&output=json&rows={max_results}"

    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        data = response.json()
        num_found = data.get('response', {}).get('numFound', 0)
        docs = data.get('response', {}).get('docs', [])

        if num_found > 0:
            results = []
            for doc in docs:
                title = doc.get('title', ['FÄƒrÄƒ titlu'])
                if isinstance(title, list):
                    title = title[0] if title else 'FÄƒrÄƒ titlu'

                identifier = doc.get('identifier', '')
                creator = doc.get('creator', ['Necunoscut'])
                if isinstance(creator, list):
                    creator = ', '.join(creator) if creator else 'Necunoscut'

                results.append({
                    'title': title,
                    'identifier': identifier,
                    'creator': creator,
                    'url': f"https://archive.org/details/{identifier}"
                })

            return True, num_found, results
        else:
            return False, 0, []

    except Exception as e:
        return False, -1, [f"Eroare: {e}"]

def process_single_file(filepath, verbose=True):
    """
    ProceseazÄƒ un singur fiÈ™ier È™i returneazÄƒ rezultatul.
    """
    search_query, filtered_words = process_filename(filepath)

    if verbose:
        print(f"\nğŸ“ {os.path.basename(filepath)}")
        print(f"   Query: '{search_query}'")

    # ÃncearcÄƒ mai multe variante de cÄƒutare
    search_variants = [
        search_query,
        ' '.join(filtered_words[:4]),  # primele 4 cuvinte
        ' '.join(filtered_words[:3]),  # primele 3 cuvinte
        f'creator:"{filtered_words[0]} {filtered_words[1]}"' if len(filtered_words) >= 2 else search_query
    ]

    best_result = None

    for i, variant in enumerate(search_variants):
        found, count, results = search_archive_org_api(variant, max_results=3)

        if found and results:
            if verbose:
                print(f"   âœ… GÄ‚SIT cu varianta {i+1}: {count} rezultate")
                for j, result in enumerate(results[:2], 1):
                    print(f"      {j}. {result['title']}")
                    print(f"         {result['url']}")

            best_result = {
                'filepath': filepath,
                'query': variant,
                'found': True,
                'count': count,
                'results': results,
                'status': 'GÄ‚SIT'
            }
            break

        # PauzÄƒ Ã®ntre cÄƒutÄƒri pentru a nu suprasolicita API-ul
        time.sleep(0.5)

    if not best_result:
        if verbose:
            print(f"   âŒ NU S-A GÄ‚SIT")

        best_result = {
            'filepath': filepath,
            'query': search_query,
            'found': False,
            'count': 0,
            'results': [],
            'status': 'NU S-A GÄ‚SIT'
        }

    return best_result

def process_directory(directory_path, file_extensions=None, max_files=None):
    """
    ProceseazÄƒ toate fiÈ™ierele dintr-un director.
    """
    if file_extensions is None:
        file_extensions = ['.pdf', '.djvu', '.epub', '.txt']

    directory = Path(directory_path)
    if not directory.exists():
        print(f"âŒ Directorul {directory_path} nu existÄƒ!")
        return []

    # GÄƒseÈ™te toate fiÈ™ierele cu extensiile specificate
    all_files = []
    for ext in file_extensions:
        all_files.extend(directory.rglob(f"*{ext}"))

    if max_files:
        all_files = all_files[:max_files]

    print(f"ğŸ” GÄƒsite {len(all_files)} fiÈ™iere pentru procesare")
    print("="*80)

    results = []
    found_count = 0

    for i, filepath in enumerate(all_files, 1):
        print(f"\n[{i}/{len(all_files)}]", end="")

        result = process_single_file(str(filepath), verbose=True)
        results.append(result)

        if result['found']:
            found_count += 1

        # PauzÄƒ Ã®ntre fiÈ™iere
        time.sleep(1)

    return results, found_count

def generate_report(results, output_file=None):
    """
    GenereazÄƒ un raport cu rezultatele.
    """
    found_results = [r for r in results if r['found']]
    not_found_results = [r for r in results if not r['found']]

    report = []
    report.append("="*80)
    report.append("RAPORT CÄ‚UTARE ARCHIVE.ORG")
    report.append("="*80)
    report.append(f"Total fiÈ™iere procesate: {len(results)}")
    report.append(f"FiÈ™iere gÄƒsite: {len(found_results)}")
    report.append(f"FiÈ™iere negÄƒsite: {len(not_found_results)}")
    report.append(f"Rata de succes: {len(found_results)/len(results)*100:.1f}%")

    if found_results:
        report.append("\n" + "="*50)
        report.append("FIÈ˜IERE GÄ‚SITE:")
        report.append("="*50)

        for result in found_results:
            filename = os.path.basename(result['filepath'])
            report.append(f"\nğŸ“š {filename}")
            report.append(f"   Query folosit: {result['query']}")
            report.append(f"   Rezultate gÄƒsite: {result['count']}")

            for i, item in enumerate(result['results'][:2], 1):
                report.append(f"   {i}. {item['title']}")
                report.append(f"      URL: {item['url']}")

    if not_found_results:
        report.append(f"\n{'='*50}")
        report.append("FIÈ˜IERE NEGÄ‚SITE:")
        report.append("="*50)

        for result in not_found_results:
            filename = os.path.basename(result['filepath'])
            report.append(f"\nâŒ {filename}")
            report.append(f"   Query Ã®ncercat: {result['query']}")

    report_text = '\n'.join(report)
    print(report_text)

    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
        print(f"\nğŸ’¾ Raportul a fost salvat Ã®n: {output_file}")

def main():
    """
    FuncÈ›ia principalÄƒ - testeazÄƒ cu exemplul dat È™i permite procesare Ã®n lot.
    """
    # Test cu exemplul dat
    filepath = r"g:\ARHIVA\C\Chelaru, Marius\Chelaru, Marius - Poarta catre poezia araba - (trad) - retail.pdf"

    print("="*80)
    print("TEST CU EXEMPLUL SPECIFICAT")
    print("="*80)

    result = process_single_file(filepath, verbose=True)

    # Exemplu procesare director (decomenteazÄƒ pentru a folosi)
    """
    print("\n" + "="*80)
    print("PROCESARE DIRECTOR")
    print("="*80)

    # ÃnlocuieÈ™te cu calea cÄƒtre directorul tÄƒu
    directory_path = r"g:\ARHIVA\C"

    results, found_count = process_directory(
        directory_path,
        file_extensions=['.pdf'],
        max_files=10  # limiteazÄƒ la primele 10 fiÈ™iere pentru test
    )

    generate_report(results, output_file="archive_org_report.txt")
    """

if __name__ == "__main__":
    main()